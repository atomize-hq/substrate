# Fixing REPL Busy-Spin and Implementing Async Agent Output: Plan & Steps

## Validation of Approach & Alternatives

The observed issue is that Substrate’s interactive REPL loop is busy-polling the TTY for input, pegging one CPU core when idle[\[1\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L9-L13). This stems from Reedline/crossterm reading a non-blocking stdin in a tight loop on macOS (and potentially other platforms) with no pause, causing \~100% CPU on one core[\[1\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L9-L13). The top priority is to eliminate this busy-spin and allow **asynchronous agent output streaming** without corrupting the user’s prompt[\[2\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/BACKLOG.md#L8-L12).

After researching common patterns, the chosen direction – an **event-driven async REPL with no polling** – is confirmed as the optimal solution. This aligns with best practices and our Phase 4 design: \- **Async/Tokio Event Loop:** Leveraging Tokio for an async REPL yields zero CPU usage when idle and cleanly handles multiple input sources[\[3\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L30-L38). The goal is to use tokio::select\! to await either user input or agent output events, instead of continuously polling[\[4\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L54-L62). This approach eliminates needless CPU wakeups and scales to multiple concurrent agent streams[\[3\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L30-L38). \- **Maintain Prompt Integrity:** Simply printing from another thread without coordination would intermix output and prompt text in ugly ways[\[5\]](https://users.rust-lang.org/t/is-it-possible-to-host-a-repl-child-process-in-rustyline/132075#:~:text=Clarifying%20question%3A%20Are%20you%20trying,comes%20from%20the%20child%20process). We must **preserve the prompt and user input** when agent messages arrive. This will be done by clearing the current line and printing the agent message, then restoring the prompt/input line – essentially what Reedline::suspend\_guard() or manual ANSI sequences (\\r and \\x1b\[K) achieve[\[6\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L71-L78). We *do* care about avoiding “the prompt disappearing behind output”[\[5\]](https://users.rust-lang.org/t/is-it-possible-to-host-a-repl-child-process-in-rustyline/132075#:~:text=Clarifying%20question%3A%20Are%20you%20trying,comes%20from%20the%20child%20process), so a coordinated redraw is necessary. \- **Reedline vs. Other Libraries:** Our plan sticks with **Reedline**, adding a background event renderer, rather than switching libraries. The Rustyline maintainer notes that Rustyline lacks a built-in way to integrate external output mid-prompt[\[7\]](https://users.rust-lang.org/t/is-it-possible-to-host-a-repl-child-process-in-rustyline/132075#:~:text=process%27s%20stdout%20in%20another%20thread,ugly%20experience%20for%20the%20user), and an attempt to do so would require heavy changes or an async fork. In fact, community advice for that problem was to consider Reedline or a custom solution[\[8\]](https://users.rust-lang.org/t/is-it-possible-to-host-a-repl-child-process-in-rustyline/132075#:~:text=You%20may%20want%20to%20look,looks%20to%20be%20well%20supported). Reedline already supports temporarily suspending the prompt for external prints, which we’ll leverage. An alternate approach like using crossterm’s EventStream directly with a custom line editor is possible, but we’d lose Reedline’s features (history, completion, etc.) during the transition[\[9\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L134-L135). Our chosen path (“non-polling renderer thread” with Reedline) achieves the goal with minimal risk and complexity[\[10\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L40-L48). \- **Cross-Platform Considerations:** The solution must work uniformly on macOS, Linux, and Windows. We will use cross-platform APIs (Tokio, crossterm, standard Rust channels) and ensure any OS-specific handling (TTY detection, socket paths vs. named pipes) is accounted for. The acceptance criteria is **\<0.1% CPU when idle, no prompt corruption, on all three OS**[\[11\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L114-L122). We’ll verify that ANSI escape-based line clearing works on Windows terminals (modern Windows 10+ consoles support ANSI sequences; crossterm enables them by default). Platform differences in agent connection (Unix domain socket vs TCP vs vsock) will be abstracted behind our “agent event source” implementation.

With these points in mind, the plan is to proceed with the **async event-loop design**, implemented in stages for safety and clarity. This approach is recommended by our design docs[\[3\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L30-L38) and avoids the pitfalls of simpler but flawed fixes (like ad-hoc sleeps or one-off threads without prompt coordination).

## Implementation Stages and Tasks

**Stage 1: Immediate Busy-Spin Mitigation**  
1\. **TTY Gating for REPL:** Modify the shell startup to only enter the interactive run\_shell loop if STDIN is a TTY. If Substrate is launched in a context with no real terminal (e.g. background service or pipe), skip initializing Reedline. Using std::io::stdin().is\_terminal() (or the atty crate) we can detect this condition[\[1\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L9-L13). When no TTY is present, the program can either run in headless mode (start the agent backend only) or exit with a message. *This prevents the busy-loop entirely for daemon use cases.*  
2\. **Backoff in Input Polling (Interim Fix):** In case we still use the current Reedline loop before full async refactor, introduce a small sleep or timed poll to avoid tight spins. For example, use crossterm::event::poll() with a timeout (50 ms), and only call event::read() if poll returns true; if poll is false (no input ready), sleep briefly (e.g. 1–5 ms)[\[1\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L9-L13). This ensures that an interactive session with an attached TTY does not consume CPU when the user isn’t typing. (On Linux, Reedline already uses a blocking read via termios raw mode, so CPU is 0% idle; on macOS, this change will break the tight EAGAIN loop.) The backoff values (poll interval, sleep duration) can be tuned to balance input responsiveness with CPU usage – e.g. 50 ms poll gives \~20 checks per second, which is negligible CPU, and \~1 ms sleep yields \<0.1% CPU[\[1\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L9-L13).  
3\. **Verify Immediate Relief:**
    *Verification (2025-10-24 14:54 UTC):* `top -b -d 1 -n 5 -p 1897886` on Fedora 40 showed the idle REPL staying at `0.0%` CPU across all samples while waiting for input.
 Before proceeding, confirm that with the above fixes, **idle CPU usage drops to \~0%** in a simple scenario. Launch substrate and do nothing; check top or powermetrics (macOS) to ensure one core is no longer pegged. This addresses the urgent energy/performance issue while we implement the full solution.

**Stage 2: Async Event Infrastructure (Prompt-Friendly)**  
1\. **Introduce Async REPL Mode (Flag):** Create a feature-flag or CLI option (e.g. \--async-repl) that enables the new async loop[\[12\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L83-L91)[\[13\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L93-L101). Initially, keep the existing sync Reedline loop as default for stability; developers can opt-in to async mode for testing. In code, this means if the flag is set, call an async\_run\_repl() function (using Tokio) instead of the standard run\_shell()[\[13\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L93-L101). We will use Tokio even in the interactive CLI because our agent communication already uses it. Ensure that the binary is built with the async feature (add a Cargo feature if needed to include tokio dependencies in the CLI).  
2\. **Async REPL Loop Implementation:** In async\_run\_repl(), use tokio::select\! to wait on multiple event sources: **(a)** user input from stdin, and **(b)** agent output events. A simplified version will use BufReader::new(tokio::io::stdin()).lines() for input, and a tokio::sync::mpsc::Receiver for agent events[\[14\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L50-L59)[\[15\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L61-L69). Pseudocode:

loop {  
    tokio::select\! {  
        Some(line) \= lines.next\_line() \=\> { /\* handle user input command \*/ },  
        Some(evt) \= agent\_events.recv() \=\> { /\* handle agent event output \*/ },  
        else \=\> break, // handle EOF or channel closure  
    }  
}

Handling an input line will involve parsing/executing the command (possibly dispatching to the agent) just like the sync path, but now this function itself is async so it can await command completion if needed. Handling an agent event means printing the message to the terminal without disrupting the REPL state. **Important:** Because we’re bypassing Reedline here, initially we won’t have fancy editing or history on this branch. The design doc notes that this minimal async mode might forego advanced line editing until full integration[\[9\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L134-L135). We can mitigate this by using a hybrid approach (see Stage 3).  
3\. **Prompt Preservation on Event Print:** Implement the logic to safely print agent messages in the middle of user input. In the pure async approach (without Reedline), this means manually managing the terminal cursor. The technique (also used by Reedline’s suspend logic) is: print a carriage return and clear line (\\r\\x1b\[K), then print the agent output (e.g. \[agent\] message), then reprint the prompt and any partially typed input buffer[\[16\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L72-L78). If using this pure async loop, we’ll need to track the current prompt and the current user input buffer. (For a first version, we might accept that input is only processed line-by-line, i.e. no editing mid-line – since .lines() won’t give us the keystrokes until Enter. In that case, prompt preservation is simpler: we only need to print a new prompt after the agent message, since there’s no partial input to restore.)  
4\. **Connect Agent Event Channel:** Initialize a channel for agent \-\> shell events. For example, an mpsc::unbounded\_channel\<AgentMessage\> can be created; the sending end will be given to whatever part of the code receives agent outputs. In async mode, you can spawn a Tokio task that listens for agent outputs (see Stage 3 below for agent integration) and pushes events into this channel. The select loop will then pick up those events and print them. Make sure to flush stdout after prints to ensure they appear immediately[\[17\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L122-L130).  
5\. **Testing Async Loop (basic):** Manually test the flag: run substrate \--async-repl and ensure that typing commands still works and that idle CPU is indeed \~0%. Since at this point the agent output might not yet be streaming, also test with a dummy source: e.g., have the agent send a simple notification on command completion that the async loop can display. This will confirm the printing logic works. We expect no more busy-spin: the Tokio runtime will park the thread when idle, so CPU stays near 0%[\[3\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L30-L38).

**Stage 3: Concurrent Agent Output Integration**  
Now that the REPL can handle multiple input sources, we integrate the real agent output stream:

1. **Agent Event Source (AgentHub or Direct):** Implement the mechanism for receiving *streaming* output/events from the world-agent. We have two possible approaches:

2. **Direct WebSocket to Agent:** If the world-agent already offers a WebSocket or similar streaming endpoint for command output, the shell can connect to it. Indeed, for PTY commands on Linux, the code already uses a WebSocket (tokio\_tungstenite) to stream the PTY output from the agent[\[18\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/crates/shell/src/lib.rs#L3398-L3411)[\[19\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/crates/shell/src/lib.rs#L3410-L3418). We can extend this idea for non-PTY commands. For example, introduce a WS endpoint in the agent that, when a command is executed, streams stdout/stderr as JSON messages or frames. The shell would initiate the command via WS and then receive a sequence of output chunks followed by an “end-of-output”/exit code message.

3. **AgentHub Broadcast Channel:** The more scalable approach (outlined in Phase 4.5) is to have a **Hub** process on the host that agents register with and publish events to[\[20\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L942-L951)[\[21\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L953-L960). In this model, the shell would subscribe (over a local socket or TCP) to a stream of AgentEvent messages. We plan to implement a minimal Hub: likely in the host-proxy or a new agent-hub service, using a Tokio broadcast::channel internally for fan-out[\[22\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L952-L960). The shell on startup would connect (e.g., to a Unix socket \~/.substrate/hub.sock or via WebSocket) and receive a live feed of agent events[\[23\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L956-L964). For now, since our immediate goal is the shell’s behavior, we can simulate this by having the world-agent send events directly to the shell’s channel (bypassing an external hub). In the future, switching to the Hub just means changing the event subscription source, not the shell’s rendering logic.

4. **Background Renderer Thread (with Reedline)**: In order to preserve the full Reedline editing experience in interactive mode, we will integrate the async output *without discarding Reedline*. This is **Path A** from the design plan: keep using the sync Reedline loop, but augment it with a background thread that prints agent events as they arrive[\[10\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L40-L48). Concretely:

5. Start an **event listener thread** when the shell initializes (only if in interactive mode with a TTY). This thread will perform a blocking receive on an events channel (to which agent outputs are sent) and render them. Because it uses blocking .recv, it **does not poll** when there are no events (idle CPU \= 0\)[\[24\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L978-L986).

6. When an event arrives, use Reedline::suspend\_guard() (or an equivalent mechanism) to safely print the message above the prompt. With Reedline, this means acquiring the suspend guard, which internally handles the “save prompt, move cursor, clear line” steps. If direct access to Reedline’s internals isn’t feasible from another thread, we can mimic it: e.g., use a static Stdout lock and the same \\r\\x1b\[K technique to clear the line, then print the event, then call an API to tell Reedline to redraw the prompt. The Phase 4.5 plan sketch uses a helper redraw\_suspended(|out| { ... }) to encapsulate this[\[25\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L980-L988)[\[26\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L990-L998). We’ll implement something similar. The printed event format can be as simple as a prefix with agent ID or name, and the content. For example:

* \[agent42\] Task completed successfully.

* This line will appear just as if another user printed to the terminal, except our logic ensures it doesn’t break the prompt. After printing, the thread (or main thread via a signal) should trigger Reedline to redraw the prompt and any current input buffer. \- **Global Channel:** We will likely use a global static sender (wrapped in a OnceCell or lazy\_static) for agent events. The world-agent execution code (when running a non-PTY command) will post events through this channel instead of (or in addition to) buffering output. For example, as the agent produces output chunks, we call AGENT\_EVENT\_TX.send(Event::Output(chunk)). The background thread’s receiver will pick these up and print. When the command finishes, a final event with the exit status (and any metadata like fs\_diff) can be sent, so the shell knows the command is complete. \- **Multiple Agents:** Design the event struct to include an agent identifier. Our minimal AgentEvent might have fields like { agent\_id, kind, data }[\[27\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L48-L56). This way, if multiple agents are connected (in the future), the output can show which agent it came from. For now, our primary “agent” is the world-agent handling shell commands, so agent\_id could be a constant or the world’s name. 3\. **Integrate with Command Execution Path:** Modify execute\_command (the non-PTY branch) to use the new async output mechanism. Currently, for macOS and Windows, exec\_non\_pty\_via\_agent\_\* functions call the agent and wait for a complete result, then print it all at once[\[28\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/crates/shell/src/lib.rs#L3574-L3582)[\[29\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/crates/shell/src/lib.rs#L3575-L3583). We will refactor this so that: \- The request to the agent includes some form of **“streaming mode”** indicator. For instance, instead of a simple HTTP POST and wait, the shell could open a WebSocket, send a “start command” message, then asynchronously receive output frames. If using the Hub, the shell would send a start request (HTTP) and then read events from the subscribed stream. \- The function should **not block** on collecting full output. Instead, it might spawn an async task (or use the background thread) to collect the output. The main thread (Reedline loop) can immediately return to prompt after sending the command, trusting that output will be rendered via events. We’ll need a mechanism to determine when the command is done to set the prompt state (e.g., maybe change prompt symbol while command is running). Possibly, we mark the prompt with an asterisk or so while a command is executing. \- Ensure that **structured logging and span finishing** still occur. When the final output/exit event arrives, we should log the command\_complete event and complete the tracing span with the exit code and any collected metadata (like fs\_diff). The design notes that tests like the JSON roundtrip of command\_start/command\_finish should still pass, meaning we must still call log\_command\_event(... "command\_complete" ...) with the right data[\[30\]](https://users.rust-lang.org/t/is-it-possible-to-host-a-repl-child-process-in-rustyline/132075#:~:text=bowen951209%20%20July%2020%2C%202025%2C,1%3A11pm%20%203)[\[31\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/crates/shell/src/lib.rs#L3582-L3591). We can do this in the event listener thread or in the async task when it receives the completion message. 4\. **Cross-Platform Event Transport:** Implement any platform-specific hooks needed for the agent event channel: \- **Linux:** Likely simplest, as we can use the existing /run/substrate.sock UDS. If the Hub is not ready, the world-agent could write outputs to the socket in chunks that the shell reads. However, since the current Linux path already directly returns the full output, we’d change it to stream (maybe reuse the PTY WS infra by treating non-PTY similarly). \- **macOS:** The agent runs in a Lima VM; the host-proxy currently tunnels HTTP. We might introduce a **WebSocket proxy** as well. E.g., use tokio\_tungstenite to connect to a VSock or TCP inside the VM that streams output. The platform\_world module on macOS can maintain a context with an open channel. In the interim, we could fall back to polling the HTTP for incremental chunks, but a better approach is enabling the agent to push via the VSock connection (possibly by upgrading to a WS protocol over the existing SSH tunnel). \- **Windows:** If/when a Windows backend exists (likely via WSL or a native agent service), similar considerations apply. Perhaps use a TCP connection (since UDS aren’t available) or named pipe for events. The Hub plan suggests a default TCP 127.0.0.1:9876 for the hub on Windows[\[32\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L964-L972). We’ll design the shell to detect OS and connect to the appropriate endpoint (Unix socket vs TCP). For now, the key is structuring our code so these differences are encapsulated. E.g., an AgentEventListener trait could have implementations for Unix and Windows that yield a mpsc::Receiver\<AgentEvent\>. The shell simply uses whichever is appropriate. This keeps the **cross-platform support seamless**. 5\. **Real-World Usage Patterns:** We should validate the solution against typical usage scenarios: \- Running a long command that produces continuous output (e.g., yes or a build process) – the output should stream live to the terminal, and the prompt should remain responsive (the user can hit Ctrl+C to interrupt, etc.). The new renderer thread must keep up with high output rates. We’ll test with a dummy agent that emits, say, 1000 events/second and ensure the UI can handle it without lag or corruption[\[33\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L1001-L1009)[\[34\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L1002-L1005). \- Multiple concurrent agents (future scenario): Start two agents that send intermittent status messages while the user types commands. The output lines from both should appear, each labeled, and the prompt should always repaint correctly on the next line. This tests the thread-safety and correctness of our suspend/redraw logic. \- Ensure that terminating the shell (Ctrl+D or exit) shuts down the event thread cleanly (join the thread to avoid orphan). Likewise, if the agent/hub connection drops, the thread should handle a channel close gracefully (exiting the loop). \- Verify that on slow terminals or high throughput, we don’t overwhelm the output (if needed, we might introduce a small yield in the renderer thread when floods of messages arrive to avoid starving the input thread – though in practice the main thread is mostly idle waiting for input). \- Confirm that **history and editing** still work when no agent output is happening (they should, as Reedline is intact), and that after an agent message prints, the user’s partially typed command is unharmed.

**Stage 4: Testing, Metrics & Rollout**  
1\. **Automated Testing:** Augment our test suite to cover the new behavior. For example, write an integration test where we simulate an agent producing two output chunks and a completion. We can hook a dummy agent by overriding the exec function to send events into the channel. Then verify the shell’s stdout contains the expected interleaved output lines in the correct order. Also test that the JSON log events (command\_start and command\_complete) are still emitted with correct timing around the streaming (the command\_start should be logged before any output, and command\_complete after final output).  
2\. **Performance & Idle Verification:** Measure idle CPU in a real scenario with the new code. Use tools like pidstat or top on Linux and macOS to ensure we meet the **\<0.1% CPU idle** target[\[33\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L1001-L1009)[\[11\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L114-L122). Also measure that a high-throughput output does not significantly affect CPU beyond the cost of printing to terminal (which is unavoidable). We expect to see the main thread mostly sleeping when idle (no more busy loop), and the event thread sleeping when no events.  
3\. **Prompt Integrity Checks:** Manually test sequences where agent output arrives exactly while the user is typing. The user’s input should remain intact. For instance, type a command but do not hit enter, and have an agent message arrive – the partial input should redraw after the message line. This ensures our suspend/redraw logic via Reedline is correct. We should also test special control characters (e.g., a long output with newlines, or an output that includes something like a carriage return) to ensure nothing odd happens with cursor positioning.  
4\. **Logging and Observability:** Ensure that we log which mode is active. On startup, print a debug or info log like “Interactive shell running in async mode” vs “sync mode”, to help with troubleshooting in the field. Also consider emitting a periodic debug log or metric for “idle loops” or event counts to detect if any polling accidentally snuck back in.  
5\. **Gradual Rollout:** Initially keep the \--async-repl flag undocumented or experimental until we’re confident. Once tested, we can flip the default: make the async path the default and require a \--no-async-repl or similar to fall back if issues arise. Eventually, remove the old sync code as per our Phase 4 migration plan[\[35\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L138-L146)[\[36\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L148-L155). The final product will always run the async event-driven REPL, ensuring efficient idle usage and real-time agent interactions.

Throughout these stages, we will continuously cross-check with our design docs to ensure we meet all **design principles**: *no polling, no blocking the Tokio executor, prompt always consistent, and full tracing integration*[\[37\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_CONCURRENT_OUTPUT_DESIGN.md#L194-L201)[\[38\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/project_management/future/PHASE_4_5_ADVANCED_FEATURES_PLAN.md#L970-L978). By following this plan, Substrate’s shell will no longer busy-spin, and it will seamlessly stream agent outputs to the user in real time, across all supported platforms – fulfilling the top priority backlog item[\[2\]](https://github.com/atomize-hq/substrate/blob/34c4d835ebbb93b087641630f0e9b35976a59837/docs/BACKLOG.md#L8-L12) with a robust solution.
